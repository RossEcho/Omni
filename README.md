# Omni
Voice-Controlled Desktop Automation

This project is inspired by J.A.R.V.I.S. from Iron Man and aims to revolutionize how we interact with our desktop environments. Leveraging the power of OpenAI's GPT-4 for understanding natural language, Whisper for accurate voice recognition, and PyAutoGUI for seamless desktop control, it creates an intuitive and efficient user experience. Simply speak your commands and watch as your computer responds, executing tasks from opening applications to managing files, all guided by visual cues on your screen.

Features

Voice Recognition: Utilizes OpenAI's Whisper model for reliable voice command interpretation.
Natural Language Processing: Employs GPT-4 to understand and process user commands in natural language.
Desktop Automation: Executes a wide range of desktop tasks using PyAutoGUI based on the processed commands.
Getting Started
in cmd run "pip install requirements.txt"
make sure to set your resolution and api key in config.py

Usage

run the code, recording 5 secs. might be a bit slow due to the model response speed 

For more details on implementation and usage, refer to the documentation within this repository.
